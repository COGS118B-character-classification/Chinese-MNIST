{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to read the data into one dataframe\n",
    "df = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    df_temp = pd.read_csv(f'../data/processed_chinese_mnist_part_{i}.csv')\n",
    "    df = df.append(df_temp)\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cn_label</th>\n",
       "      <th>value</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>零</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>九</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>十</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>百</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>千</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4099 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label cn_label  value    0    1    2    3    4    5    6  ...  4086  4087  \\\n",
       "0      1        零      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1     10        九      9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2     11        十     10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3     12        百    100  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4     13        千   1000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "   4088  4089  4090  4091  4092  4093  4094  4095  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 4099 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split, load everything in pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 4099), (3000, 4099))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_ratio = 0.8\n",
    "df_train = df.iloc[:int(len(df) * train_test_ratio)]\n",
    "df_test = df.iloc[int(len(df) * train_test_ratio):]\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternatively (no longer used)\n",
    "\n",
    "# train_arr_data = df_train.iloc[:, 3:].values.reshape(12000, 64, 64)\n",
    "# test_arr_data = df_test.iloc[:, 3:].values.reshape(3000, 64, 64)\n",
    "\n",
    "# train_arr_data.shape, test_arr_data.shape\n",
    "\n",
    "# train_arr_target = df_train.iloc[:, 0].values\n",
    "# test_arr_target = df_test.iloc[:, 0].values\n",
    "\n",
    "# train_arr_target.shape, test_arr_target.shape\n",
    "\n",
    "# device = 'cpu'\n",
    "\n",
    "# training_data = torch.FloatTensor(train_arr_data).to(device)\n",
    "# training_data.shape\n",
    "\n",
    "# training_target = torch.LongTensor(train_arr_target).to(device)\n",
    "# train_arr_target.shape\n",
    "\n",
    "# testing_data = torch.FloatTensor(test_arr_data).to(device)\n",
    "# testing_target = torch.LongTensor(test_arr_target).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDataset():\n",
    "    \"\"\"\n",
    "    Dataset that contain the target, data as instance variables to feed \n",
    "    into torch dataloader. In order to properly load these properties, we\n",
    "    need it to have at least have the len() method and make sure that it is \n",
    "    subscriptable.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_df):\n",
    "        \n",
    "        input_df = input_df.reset_index(drop = True)\n",
    "        \n",
    "        self.target = input_df['label']\n",
    "        \n",
    "        self.data = (input_df.iloc[:, 3:].values\n",
    "                    ).reshape(len(input_df), 1, 64, 64).astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.target)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        return self.data[i], self.target[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataSet = ImgDataset(df_train)\n",
    "testDataSet = ImgDataset(df_test)\n",
    "\n",
    "# Define batch size, which is how many samples you use for training in one iteration\n",
    "batch_size_train = 32 \n",
    "\n",
    "batch_size_test = 1024 \n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(trainDataSet,\n",
    "                                           batch_size=batch_size_train, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testDataSet,\n",
    "                                          batch_size=batch_size_test, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7491643ca4c54eb6be2505ec7f7a4a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 64, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "counter = 0\n",
    "for batch_idx, (data, target) in enumerate(iterator):\n",
    "    dataa, target = data.to('cpu'), target.to('cpu')\n",
    "    break\n",
    "dataa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 30, 30])\n",
      "torch.Size([32, 30, 13, 13])\n",
      "torch.Size([32, 5070])\n",
      "torch.Size([32, 300])\n"
     ]
    }
   ],
   "source": [
    "test = nn.MaxPool2d(2, 2)(F.relu(nn.Conv2d(1, 10, (5, 5))(dataa)))\n",
    "print(test.shape) #32, 20, 20, 20\n",
    "test = nn.MaxPool2d(2, 2)(F.relu(nn.Conv2d(10, 30, (5, 5))(test)))\n",
    "print(test.shape) #32, 50, 8, 8\n",
    "test = test.view(-1, 30 * 13 * 13)\n",
    "print(test.shape) #32, 3200\n",
    "test = F.relu(nn.Linear(5070, 300)(test))\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50 * 8 * 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval= 10000):\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        \n",
    "def test(model, device, test_loader, num_epoch = None, print_ = False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    if print_: print('Epoch {}: Test set Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        num_epoch,\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    This class defines the deep learning model that extends a Module class\n",
    "      The constructor of  class defines the layers of the model. \n",
    "      The forward() function defines how to forward propagate \n",
    "      input through the defined layers of the model.\n",
    "      Many layers are available, such as Linear for fully connected layers, \n",
    "      Conv2d for convolutional layers, and MaxPool2d for pooling layers.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #initialize drop out function\n",
    "        self.dropout = nn.Dropout(p = 0.4)\n",
    "        #kernel size 5 and maxPool2d (2, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        #starting shape: 32 (batch size), 1, 30, 30\n",
    "        self.conv1 = nn.Conv2d(1, 5, (5, 5)) \n",
    "        #1 channel to 5 channel, kernel size 5\n",
    "        self.conv2 = nn.Conv2d(5, 30, (5, 5)) \n",
    "        #5 channel to 30 channel, kernel size 5\n",
    "        \n",
    "        #similar to the coding tutorial, using 3 linear layers to reduce to 10 final output\n",
    "        #automatically cut down to 10 units\n",
    "        self.fc1 = nn.Linear(5070, 300)\n",
    "        self.fc2 = nn.Linear(300, 50)\n",
    "        self.fc3 = nn.Linear(50, 20)\n",
    "        self.activation = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.dropout(self.conv1(x))))\n",
    "        #shape: 32, 20, 30, 30\n",
    "        x = self.pool(F.relu(self.dropout(self.conv2(x))))\n",
    "        #shape: #32, 100, 13, 13\n",
    "        x = x.view(-1, 5070) #shape 32, 5070\n",
    "        x = F.relu(self.fc1(x)) #shape 32, 300\n",
    "        x = F.relu(self.fc2(x)) #shape 32, 50\n",
    "        x = self.activation(self.fc3(x)) #shape 32, 20\n",
    "        return x\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Test set Average loss: 1.3571, Accuracy: 1715/3000 (57%)\n",
      "Epoch 10: Test set Average loss: 0.6616, Accuracy: 2398/3000 (80%)\n",
      "Epoch 15: Test set Average loss: 0.4985, Accuracy: 2536/3000 (85%)\n",
      "Epoch 20: Test set Average loss: 0.6458, Accuracy: 2374/3000 (79%)\n",
      "Epoch 25: Test set Average loss: 0.4885, Accuracy: 2539/3000 (85%)\n",
      "Epoch 30: Test set Average loss: 0.4612, Accuracy: 2576/3000 (86%)\n",
      "Epoch 35: Test set Average loss: 0.5482, Accuracy: 2527/3000 (84%)\n",
      "Epoch 40: Test set Average loss: 0.5273, Accuracy: 2547/3000 (85%)\n",
      "Epoch 45: Test set Average loss: 0.5861, Accuracy: 2508/3000 (84%)\n",
      "Epoch 50: Test set Average loss: 0.4752, Accuracy: 2582/3000 (86%)\n",
      "Epoch 55: Test set Average loss: 0.5341, Accuracy: 2557/3000 (85%)\n",
      "Epoch 60: Test set Average loss: 0.4166, Accuracy: 2642/3000 (88%)\n",
      "Epoch 65: Test set Average loss: 0.4415, Accuracy: 2658/3000 (89%)\n",
      "Epoch 70: Test set Average loss: 0.5347, Accuracy: 2568/3000 (86%)\n",
      "Epoch 75: Test set Average loss: 0.4375, Accuracy: 2652/3000 (88%)\n",
      "Epoch 80: Test set Average loss: 0.4264, Accuracy: 2660/3000 (89%)\n",
      "Epoch 85: Test set Average loss: 0.4564, Accuracy: 2641/3000 (88%)\n",
      "Epoch 90: Test set Average loss: 0.4124, Accuracy: 2688/3000 (90%)\n",
      "Epoch 95: Test set Average loss: 0.4056, Accuracy: 2690/3000 (90%)\n",
      "Epoch 100: Test set Average loss: 0.4555, Accuracy: 2631/3000 (88%)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.8\n",
    "device = \"cuda\"\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "num_epoch = 100\n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        test(model, device, test_loader, epoch, print_ = True)\n",
    "    else:\n",
    "        test(model, device, test_loader, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
